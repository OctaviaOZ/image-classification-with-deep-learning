{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Milestone 03 - TF Image Classification - Single Layer.ipynb","provenance":[{"file_id":"1e9vPPBDi2Dh7xY-jRtZuNJsVnY2KbjZQ","timestamp":1589657859360},{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb","timestamp":1587464049650}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","pycharm":{"stem_cell":{"cell_type":"raw","source":[],"metadata":{"collapsed":false}}}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"u_9-IqixV2JS"},"source":["# Load images"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"c6OTNTsgV2JZ"},"source":["This tutorial provides a simple example of how to load an image dataset using `tf.data`.\n","\n","The dataset used in this example is distributed as directories of images, with one class of image per directory."]},{"cell_type":"code","metadata":{"id":"uy11wZAILm14"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hoQQiZDB6URn"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"IEHtFUxLWdqx"},"source":["%mkdir data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFDAX_J5IitW"},"source":["!unzip -q /gdrive/MyDrive/kaggle_cars_data.zip "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KIkPkiB_URLP"},"source":["# Time magic\n","!pip install ipython-autotime\n","%load_ext autotime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SF1EcovsbD2t"},"source":["!pip install -U tensorboard_plugin_profile\n","# Load the TensorBoard notebook extension.\n","%load_ext tensorboard"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3vhAMaIOBIee"},"source":["from datetime import datetime\n","from packaging import version\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","print(f\"Using TF version: {tf.__version__}\")\n","assert version.parse(tf.__version__).release[0] >= 2, \\\n","    \"This notebook requires TensorFlow 2.0 or above.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIksPgtT8B6B"},"source":["from PIL import Image\n","\n","import IPython.display as display\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import pathlib"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rI2wcJxeKnj"},"source":["device_name = tf.test.gpu_device_name()\n","if not device_name:\n","    raise SystemError('GPU device not found')\n","    \n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KT6CcaqgQewg"},"source":["AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wO0InzL66URu"},"source":["### Retrieve the images\n","\n","Before you start any training, you will need a set of images to teach the network about the new classes you want to recognize."]},{"cell_type":"code","metadata":{"id":"rN-Pc6Zd6awg"},"source":["root_path = \"./data\"\n","\n","train_data_dir = f\"{root_path}/train/\"\n","train_data_dir = pathlib.Path(train_data_dir)\n","\n","val_data_dir = f\"{root_path}/validation/\"\n","val_data_dir = pathlib.Path(val_data_dir)\n","\n","test_data_dir = f\"{root_path}/test/\"\n","test_data_dir = pathlib.Path(test_data_dir)\n","\n","print(f\"Training data from path: {train_data_dir}, Validation data from path: {val_data_dir}, Test data from path: {test_data_dir}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhewYCxhXQBX"},"source":["train_image_count = len(list(train_data_dir.glob('*/*.jpg')))\n","test_image_count = len(list(test_data_dir.glob('*/*.jpg')))\n","val_image_count = len(list(val_data_dir.glob('*/*.jpg')))\n","\n","print(f\"Number of train images: {train_image_count}, Number of val images: {val_image_count}, Number of test images: {test_image_count}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJ1HKKdR4A7c"},"source":["class_names = np.array([item.name for item in train_data_dir.glob('*')])\n","print(f\"Class names: {class_names}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Y5iu4OBQSjF"},"source":["for fol in class_names:\n","  print (f\"Folder {fol} has {len(list(train_data_dir.glob('%s/*.jpg' % fol)))} images\")\n","\n","for fol in class_names:\n","  print (f\"Folder {fol} has {len(list(val_data_dir.glob('%s/*.jpg' % fol)))} images\")\n","\n","for fol in class_names:\n","  print (f\"Folder {fol} has {len(list(test_data_dir.glob('%s/*.jpg' % fol)))} images\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zf695or-Flq"},"source":["batch_size = 32\n","img_height = 100\n","img_width = 100\n","steps_per_epoch = np.ceil(train_image_count/batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxS1cLzM8mEp"},"source":["## Load using `tf.data`"]},{"cell_type":"markdown","metadata":{"id":"Ylj9fgkamgWZ"},"source":["The above `keras.preprocessing` method is convienient, but has three downsides: \n","\n","1. It's slow. See the performance section below.\n","1. It lacks fine-grained control.\n","1. It is not well integrated with the rest of TensorFlow."]},{"cell_type":"markdown","metadata":{"id":"IIG5CPaULegg"},"source":["To load the files as a `tf.data.Dataset` first create a dataset of the file paths:"]},{"cell_type":"code","metadata":{"id":"lAkQp5uxoINu"},"source":["train_list_ds = tf.data.Dataset.list_files(str(train_data_dir/'*/*'))\n","val_list_ds = tf.data.Dataset.list_files(str(val_data_dir/'*/*'))\n","test_list_ds = tf.data.Dataset.list_files(str(test_data_dir/'*/*'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"coORvEH-NGwc"},"source":["for f in train_list_ds.take(3):\n","  print(f.numpy())\n","\n","for f in val_list_ds.take(3):\n","  print(f.numpy())\n","\n","for f in test_list_ds.take(3):\n","  print(f.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"91CPfUUJ_8SZ"},"source":["Write a short pure-tensorflow function that converts a file path to an `(img, label)` pair:"]},{"cell_type":"code","metadata":{"id":"arSQzIey-4D4"},"source":["def get_label(file_path):\n","  # convert the path to a list of path components\n","  parts = tf.strings.split(file_path, os.path.sep)\n","  # The second to last is the class-directory\n","  return parts[-2] == class_names[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGlq4IP4Aktb","collapsed":true},"source":["def decode_img(img):\n","  # convert the compressed string to a 3D uint8 tensor\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","  # resize the image to the desired size.\n","  return tf.image.resize(img, [img_width, img_height])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-xhBRgvNqRRe"},"source":["def process_path(file_path):\n","  label = get_label(file_path)\n","  # load the raw data from the file as a string\n","  img = tf.io.read_file(file_path)\n","  img = decode_img(img)\n","  return img, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S9a5GpsUOBx8"},"source":["Use `Dataset.map` to create a dataset of `image, label` pairs:"]},{"cell_type":"code","metadata":{"id":"3SDhbo8lOBQv"},"source":["# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n","train_labeled_ds = train_list_ds.map(process_path, \n","                                     num_parallel_calls=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxrl0lGdnpRz"},"source":["for image, label in train_labeled_ds.take(1):\n","  print(\"Image shape: \", image.numpy().shape)\n","  print(\"Label: \", label.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Ew4t6q1aCqr"},"source":["# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n","val_labeled_ds = val_list_ds.map(process_path, \n","                                 num_parallel_calls=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvN1fj8NaLta"},"source":["# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n","test_labeled_ds = test_list_ds.map(process_path, \n","                                   num_parallel_calls=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYGCgJuR_9Qp"},"source":["### Basic methods for training"]},{"cell_type":"markdown","metadata":{"id":"wwZavzgsIytz"},"source":["To train a model with this dataset you will want the data:\n","\n","* To be well shuffled.\n","* To be batched.\n","* Batches to be available as soon as possible.\n","\n","These features can be easily added using the `tf.data` api."]},{"cell_type":"code","metadata":{"id":"uZmZJx8ePw_5"},"source":["def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n","  # This is a small dataset, only load it once, and keep it in memory.\n","  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n","  # fit in memory.\n","  if cache:\n","    if isinstance(cache, str):\n","      ds = ds.cache(cache)\n","    else:\n","      ds = ds.cache()\n","\n","  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","  # Repeat forever\n","  ds = ds.repeat()\n","\n","  ds = ds.batch(batch_size)\n","\n","  # `prefetch` lets the dataset fetch batches in the background while the model\n","  # is training.\n","  ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","  return ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"toFeGeddcd3O"},"source":["def prepare_for_testing(ds, cache=True):\n","  # This is a small dataset, only load it once, and keep it in memory.\n","  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n","  # fit in memory.\n","  if cache:\n","    if isinstance(cache, str):\n","      ds = ds.cache(cache)\n","    else:\n","      ds = ds.cache()\n","\n","  ds = ds.batch(batch_size)\n","\n","  # `prefetch` lets the dataset fetch batches in the background while the model\n","  # is training.\n","  ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","  return ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUPEOic3SiK6"},"source":["def show_batch(image_batch, label_batch):\n","  plt.figure(figsize=(10,10))\n","  for n in range(25):\n","      ax = plt.subplot(5,5,n+1)\n","      plt.imshow(image_batch[n])\n","      plt.title(class_names[0] if label_batch[n]==True else class_names[1])\n","    #   plt.title(class_names[label_batch[n]==class_names[0]][0].title())\n","      plt.axis('off')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UN_Dnl72YNIj"},"source":["train_ds = prepare_for_training(train_labeled_ds)\n","\n","image_batch, label_batch = next(iter(train_ds))\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6GkfQ53Zxo5"},"source":["val_ds = prepare_for_testing(val_labeled_ds)\n","\n","image_batch, label_batch = next(iter(val_ds))\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"datRCun9ar67"},"source":["test_ds = prepare_for_testing(test_labeled_ds)\n","\n","image_batch, label_batch = next(iter(test_ds))\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMVnoBcG_NlQ"},"source":["## Performance\n","\n","Note: This section just shows a couple of easy tricks that may help performance. For an in depth guide see [Input Pipeline Performance](../../guide/performance/datasets)."]},{"cell_type":"markdown","metadata":{"id":"oNmQqgGhLWie"},"source":["To investigate, first here's a function to check the performance of our datasets:"]},{"cell_type":"code","metadata":{"id":"_gFVe1rp_MYr"},"source":["import time\n","default_timeit_steps = 100\n","\n","def timeit(ds, steps=default_timeit_steps):\n","  start = time.time()\n","  it = iter(ds)\n","  for i in range(steps):\n","    batch = next(it)\n","    if i%10 == 0:\n","      print('.',end='')\n","  print()\n","  end = time.time()\n","\n","  duration = end-start\n","  print(\"{} batches: {} s\".format(steps, duration))\n","  print(\"{:0.5f} Images/s\".format(batch_size*steps/duration))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_rg8txp1IbU"},"source":["input_shape = (100, 100, 3)\n","num_outputs = 1\n","num_epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfPD0CdKT8cw"},"source":["def get_model(input_shape, num_neurons, num_outputs):\n","    model = keras.Sequential([\n","        keras.layers.Flatten(input_shape=input_shape),\n","        keras.layers.Dense(num_neurons, activation='relu'),\n","        keras.layers.Dense(num_outputs)\n","    ])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yHMpsbahUHt_"},"source":["num_neurons = 64\n","one_layer_64 = get_model(input_shape, num_neurons, num_outputs)\n","one_layer_64.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","logdir = f\"logs/scalars/one_layer_{num_neurons}\"\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n","                                                   histogram_freq = 1,\n","                                                   profile_batch = '500,520')\n","\n","training_history = one_layer_64.fit(\n","    train_ds, \n","    validation_data=val_ds, \n","    epochs=num_epochs,\n","    steps_per_epoch=steps_per_epoch,\n","    callbacks=[tensorboard_callback])\n","\n","print(f\"Average test loss: {np.average(training_history.history['loss'])}\")\n","val_loss, val_acc = one_layer_64.evaluate(val_ds, verbose=2)\n","test_loss, test_acc = one_layer_64.evaluate(test_ds, verbose=2)\n","\n","print(f\"\\nTest accuracy: {test_acc}\")\n","print(f\"\\nValidation accuracy: {val_acc}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YgRaSxBVhoZ6"},"source":["num_neurons = 128\n","one_layer_128 = get_model(input_shape, num_neurons, num_outputs)\n","one_layer_128.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","logdir = f\"logs/scalars/one_layer_{num_neurons}\"\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n","                                                   histogram_freq = 1,\n","                                                   profile_batch = '500,520')\n","\n","training_history = one_layer_128.fit(\n","    train_ds, \n","    validation_data=val_ds, \n","    epochs=num_epochs,\n","    steps_per_epoch=steps_per_epoch,\n","    callbacks=[tensorboard_callback])\n","\n","print(f\"Average test loss: {np.average(training_history.history['loss'])}\")\n","val_loss, val_acc = one_layer_128.evaluate(val_ds, verbose=2)\n","test_loss, test_acc = one_layer_128.evaluate(test_ds, verbose=2)\n","\n","print(f\"\\nTest accuracy: {test_acc}\")\n","print(f\"\\nValidation accuracy: {val_acc}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYO50NDIiQIa"},"source":["num_neurons = 256\n","one_layer_256 = get_model(input_shape, num_neurons, num_outputs)\n","one_layer_256.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","logdir = f\"logs/scalars/one_layer_{num_neurons}\"\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n","                                                   histogram_freq = 1,\n","                                                   profile_batch = '500,520')\n","\n","training_history = one_layer_256.fit(\n","    train_ds, \n","    validation_data=val_ds, \n","    epochs=num_epochs,\n","    steps_per_epoch=steps_per_epoch,\n","    callbacks=[tensorboard_callback])\n","\n","print(f\"Average test loss: {np.average(training_history.history['loss'])}\")\n","val_loss, val_acc = one_layer_256.evaluate(val_ds, verbose=2)\n","test_loss, test_acc = one_layer_256.evaluate(test_ds, verbose=2)\n","\n","print(f\"\\nTest accuracy: {test_acc}\")\n","print(f\"\\nValidation accuracy: {val_acc}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"enU6dYObiaHZ"},"source":["num_neurons = 512\n","one_layer_512 = get_model(input_shape, num_neurons, num_outputs)\n","one_layer_512.compile(optimizer='adam',\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","logdir = f\"logs/scalars/one_layer_{num_neurons}\"\n","tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n","                                                   histogram_freq = 1,\n","                                                   profile_batch = '500,520')\n","\n","training_history = one_layer_512.fit(\n","    train_ds, \n","    validation_data=val_ds, \n","    epochs=num_epochs,\n","    steps_per_epoch=steps_per_epoch,\n","    callbacks=[tensorboard_callback])\n","\n","print(f\"Average test loss: {np.average(training_history.history['loss'])}\")\n","val_loss, val_acc = one_layer_512.evaluate(val_ds, verbose=2)\n","test_loss, test_acc = one_layer_512.evaluate(test_ds, verbose=2)\n","\n","print(f\"\\nTest accuracy: {test_acc}\")\n","print(f\"\\nValidation accuracy: {val_acc}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L7mGVR77fMY6"},"source":["%tensorboard --logdir logs/scalars"],"execution_count":null,"outputs":[]}]}